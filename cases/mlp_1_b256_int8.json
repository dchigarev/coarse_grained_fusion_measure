{
  "version": "3.5.0",
  "engine_kind": "cpu",
  "fpmath_mode": "strict",
  "input_ports": [
    2, 
    5, 
    8, 
    15, 
    18, 
    25, 
    28
  ],
  "output_ports": [
    32
  ],
  "graph": [
    {
      "id": 2,
      "name": "dequantize_input_layer0",
      "kind": "Dequantize",
      "attrs": {
        "axis": {
          "type": "s64",
          "value": 0
        },
        "qtype": {
          "type": "string",
          "value": "per_tensor"
        },
        "zps": {
          "type": "s64[]",
          "value": [
            2
          ]
        },
        "scales": {
          "type": "f32[]",
          "value": [
            0.12
          ]
        }
      },
      "inputs": [
        {
          "id": 2,
          "dtype": "u8",
          "shape": [
            256, 
            13
          ],
          "stride": [
            13, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ],
      "outputs": [
        {
          "id": 3,
          "dtype": "f32",
          "shape": [
            256, 
            13
          ],
          "stride": [
            13, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 4,
      "name": "dequantize_weight_layer0",
      "kind": "Dequantize",
      "attrs": {
        "axis": {
          "type": "s64",
          "value": 1
        },
        "qtype": {
          "type": "string",
          "value": "per_channel"
        },
        "zps": {
          "type": "s64[]",
          "value": [
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0
          ]
        },
        "scales": {
          "type": "f32[]",
          "value": [
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12
          ]
        }
      },
      "inputs": [
        {
          "id": 5,
          "dtype": "s8",
          "shape": [
            13, 
            512
          ],
          "stride": [
            512, 
            1
          ],
          "layout_type": "strided",
          "property_type": "constant"
        }
      ],
      "outputs": [
        {
          "id": 6,
          "dtype": "f32",
          "shape": [
            13, 
            512
          ],
          "stride": [
            512, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 6,
      "name": "matmul_layer0",
      "kind": "MatMul",
      "attrs": {
        "transpose_a": {
          "type": "bool",
          "value": 0
        },
        "transpose_b": {
          "type": "bool",
          "value": 0
        }
      },
      "inputs": [
        {
          "id": 3,
          "dtype": "f32",
          "shape": [
            256, 
            13
          ],
          "stride": [
            13, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }, 
        {
          "id": 6,
          "dtype": "f32",
          "shape": [
            13, 
            512
          ],
          "stride": [
            512, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }, 
        {
          "id": 8,
          "dtype": "f32",
          "shape": [
            512
          ],
          "stride": [
            1
          ],
          "layout_type": "strided",
          "property_type": "constant"
        }
      ],
      "outputs": [
        {
          "id": 9,
          "dtype": "f32",
          "shape": [
            256, 
            512
          ],
          "stride": [
            512, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 7,
      "name": "activation_layer0",
      "kind": "ReLU",
      "attrs": {},
      "inputs": [
        {
          "id": 9,
          "dtype": "f32",
          "shape": [
            256, 
            512
          ],
          "stride": [
            512, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ],
      "outputs": [
        {
          "id": 10,
          "dtype": "f32",
          "shape": [
            256, 
            512
          ],
          "stride": [
            512, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 9,
      "name": "quantize_input_layer1",
      "kind": "Quantize",
      "attrs": {
        "axis": {
          "type": "s64",
          "value": 0
        },
        "qtype": {
          "type": "string",
          "value": "per_tensor"
        },
        "zps": {
          "type": "s64[]",
          "value": [
            2
          ]
        },
        "scales": {
          "type": "f32[]",
          "value": [
            0.12
          ]
        }
      },
      "inputs": [
        {
          "id": 10,
          "dtype": "f32",
          "shape": [
            256, 
            512
          ],
          "stride": [
            512, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ],
      "outputs": [
        {
          "id": 12,
          "dtype": "u8",
          "shape": [
            256, 
            512
          ],
          "stride": [
            512, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 10,
      "name": "dequantize_input_layer1",
      "kind": "Dequantize",
      "attrs": {
        "axis": {
          "type": "s64",
          "value": 0
        },
        "qtype": {
          "type": "string",
          "value": "per_tensor"
        },
        "zps": {
          "type": "s64[]",
          "value": [
            2
          ]
        },
        "scales": {
          "type": "f32[]",
          "value": [
            0.12
          ]
        }
      },
      "inputs": [
        {
          "id": 12,
          "dtype": "u8",
          "shape": [
            256, 
            512
          ],
          "stride": [
            512, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ],
      "outputs": [
        {
          "id": 13,
          "dtype": "f32",
          "shape": [
            256, 
            512
          ],
          "stride": [
            512, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 12,
      "name": "dequantize_weight_layer1",
      "kind": "Dequantize",
      "attrs": {
        "axis": {
          "type": "s64",
          "value": 1
        },
        "qtype": {
          "type": "string",
          "value": "per_channel"
        },
        "zps": {
          "type": "s64[]",
          "value": [
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0
          ]
        },
        "scales": {
          "type": "f32[]",
          "value": [
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12
          ]
        }
      },
      "inputs": [
        {
          "id": 15,
          "dtype": "s8",
          "shape": [
            512, 
            256
          ],
          "stride": [
            256, 
            1
          ],
          "layout_type": "strided",
          "property_type": "constant"
        }
      ],
      "outputs": [
        {
          "id": 16,
          "dtype": "f32",
          "shape": [
            512, 
            256
          ],
          "stride": [
            256, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 14,
      "name": "matmul_layer1",
      "kind": "MatMul",
      "attrs": {
        "transpose_a": {
          "type": "bool",
          "value": 0
        },
        "transpose_b": {
          "type": "bool",
          "value": 0
        }
      },
      "inputs": [
        {
          "id": 13,
          "dtype": "f32",
          "shape": [
            256, 
            512
          ],
          "stride": [
            512, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }, 
        {
          "id": 16,
          "dtype": "f32",
          "shape": [
            512, 
            256
          ],
          "stride": [
            256, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }, 
        {
          "id": 18,
          "dtype": "f32",
          "shape": [
            256
          ],
          "stride": [
            1
          ],
          "layout_type": "strided",
          "property_type": "constant"
        }
      ],
      "outputs": [
        {
          "id": 19,
          "dtype": "f32",
          "shape": [
            256, 
            256
          ],
          "stride": [
            256, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 15,
      "name": "activation_layer1",
      "kind": "ReLU",
      "attrs": {},
      "inputs": [
        {
          "id": 19,
          "dtype": "f32",
          "shape": [
            256, 
            256
          ],
          "stride": [
            256, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ],
      "outputs": [
        {
          "id": 20,
          "dtype": "f32",
          "shape": [
            256, 
            256
          ],
          "stride": [
            256, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 17,
      "name": "quantize_input_layer2",
      "kind": "Quantize",
      "attrs": {
        "axis": {
          "type": "s64",
          "value": 0
        },
        "qtype": {
          "type": "string",
          "value": "per_tensor"
        },
        "zps": {
          "type": "s64[]",
          "value": [
            2
          ]
        },
        "scales": {
          "type": "f32[]",
          "value": [
            0.12
          ]
        }
      },
      "inputs": [
        {
          "id": 20,
          "dtype": "f32",
          "shape": [
            256, 
            256
          ],
          "stride": [
            256, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ],
      "outputs": [
        {
          "id": 22,
          "dtype": "u8",
          "shape": [
            256, 
            256
          ],
          "stride": [
            256, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 18,
      "name": "dequantize_input_layer2",
      "kind": "Dequantize",
      "attrs": {
        "axis": {
          "type": "s64",
          "value": 0
        },
        "qtype": {
          "type": "string",
          "value": "per_tensor"
        },
        "zps": {
          "type": "s64[]",
          "value": [
            2
          ]
        },
        "scales": {
          "type": "f32[]",
          "value": [
            0.12
          ]
        }
      },
      "inputs": [
        {
          "id": 22,
          "dtype": "u8",
          "shape": [
            256, 
            256
          ],
          "stride": [
            256, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ],
      "outputs": [
        {
          "id": 23,
          "dtype": "f32",
          "shape": [
            256, 
            256
          ],
          "stride": [
            256, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 20,
      "name": "dequantize_weight_layer2",
      "kind": "Dequantize",
      "attrs": {
        "axis": {
          "type": "s64",
          "value": 1
        },
        "qtype": {
          "type": "string",
          "value": "per_channel"
        },
        "zps": {
          "type": "s64[]",
          "value": [
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0, 
            0
          ]
        },
        "scales": {
          "type": "f32[]",
          "value": [
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12, 
            0.12
          ]
        }
      },
      "inputs": [
        {
          "id": 25,
          "dtype": "s8",
          "shape": [
            256, 
            128
          ],
          "stride": [
            128, 
            1
          ],
          "layout_type": "strided",
          "property_type": "constant"
        }
      ],
      "outputs": [
        {
          "id": 26,
          "dtype": "f32",
          "shape": [
            256, 
            128
          ],
          "stride": [
            128, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 22,
      "name": "matmul_layer2",
      "kind": "MatMul",
      "attrs": {
        "transpose_a": {
          "type": "bool",
          "value": 0
        },
        "transpose_b": {
          "type": "bool",
          "value": 0
        }
      },
      "inputs": [
        {
          "id": 23,
          "dtype": "f32",
          "shape": [
            256, 
            256
          ],
          "stride": [
            256, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }, 
        {
          "id": 26,
          "dtype": "f32",
          "shape": [
            256, 
            128
          ],
          "stride": [
            128, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }, 
        {
          "id": 28,
          "dtype": "f32",
          "shape": [
            128
          ],
          "stride": [
            1
          ],
          "layout_type": "strided",
          "property_type": "constant"
        }
      ],
      "outputs": [
        {
          "id": 29,
          "dtype": "f32",
          "shape": [
            256, 
            128
          ],
          "stride": [
            128, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 23,
      "name": "activation_layer2",
      "kind": "ReLU",
      "attrs": {},
      "inputs": [
        {
          "id": 29,
          "dtype": "f32",
          "shape": [
            256, 
            128
          ],
          "stride": [
            128, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ],
      "outputs": [
        {
          "id": 30,
          "dtype": "f32",
          "shape": [
            256, 
            128
          ],
          "stride": [
            128, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }, 
    {
      "id": 25,
      "name": "quantize_output",
      "kind": "Quantize",
      "attrs": {
        "axis": {
          "type": "s64",
          "value": 0
        },
        "qtype": {
          "type": "string",
          "value": "per_tensor"
        },
        "zps": {
          "type": "s64[]",
          "value": [
            2
          ]
        },
        "scales": {
          "type": "f32[]",
          "value": [
            0.12
          ]
        }
      },
      "inputs": [
        {
          "id": 30,
          "dtype": "f32",
          "shape": [
            256, 
            128
          ],
          "stride": [
            128, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ],
      "outputs": [
        {
          "id": 32,
          "dtype": "u8",
          "shape": [
            256, 
            128
          ],
          "stride": [
            128, 
            1
          ],
          "layout_type": "strided",
          "property_type": "undef"
        }
      ]
    }
  ]
}